---
title: "Project DS502"
author: "Mahdi Alouane and Rahul Pande"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      tidy=TRUE,
                      fig.align='center',
                      tidy.opts=list(width.cutoff=60))
# https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html
```

```{r , echo =TRUE}
train.data <- read.csv('./bigmart_train.csv', stringsAsFactors = FALSE, na.strings = c(""))
test.data <- read.csv('./bigmart_test.csv', stringsAsFactors = FALSE, na.strings = c(""))
```

```{r , echo =TRUE}
check.na.values <- function(df){
  colSums(apply(df, 2, is.na))
}
check.na.values(train.data)
check.na.values(test.data)
```

We have missing values in `Item_Weight` and `Outlet_Size`.


Now, we check the frequencies of categorical variables.

```{r , echo =TRUE}
col_types = lapply(train.data, class)
char_cols = names(col_types[col_types == 'character'])
lapply(train.data[, setdiff(char_cols, c("Item_Identifier"))], table)
```


We aggregate on outlet level to impute outlet size
```{r , echo =TRUE}
setdiff(unique(train.data$Outlet_Identifier), unique(test.data$Outlet_Identifier))
setdiff(unique(test.data$Outlet_Identifier), unique(train.data$Outlet_Identifier))
```

We see that there are no new stores in the test data that are not already encountered in the training data.

```{r , echo =TRUE}
library(tidyverse)
item_weights <- train.data %>%
  group_by(Item_Identifier) %>%
  summarise(
    l_u_weights = length(unique(Item_Weight)),
    u_weights = paste(sort(unique(Item_Weight), na.last = TRUE), collapse = " | ")) %>%
  arrange(desc(u_weights))

head(item_weights, 10)
```

We see that in some places weights are NA whereas it is not NA in other rows for the same item. We can just use weights from other observations where weight is not NA (For the same item). For this purpose the whole train and test datasets have been used to impute the missing information. Hence, we define the following function for treating these missing values.

```{r}
fill_missing_values <- function(file) {
  train_file <- read.csv("./bigmart_train.csv")
  test_file <- read.csv("./bigmart_test.csv")
  all <- rbind(subset(train_file, select = -Item_Outlet_Sales), test_file)
  train_file_i <- which(is.na(file$Item_Weight))
  
  for (i in train_file_i) {
    id <- file[i,]$Item_Identifier
    weight <- all[ all$Item_Identifier == as.character(id) & !is.na(all$Item_Weight),]$Item_Weight[1]
    file[i,]$Item_Weight <- weight
  }
  
  return (file)
  
}
```

Then, we call it and check if the problem is resolved.

```{r , echo =TRUE}
train.data <- fill_missing_values(train.data)
test.data <- fill_missing_values(test.data)
check.na.values(train.data)
check.na.values(test.data)
```

Since, there is no more missing values for the feature `Item_Weight`, we treat in the following section the missing values for the feature `Outlet_Size`.

Given that `Outlet_Size` is an outlet specific attribute, we first begin by printing all the outlets available in our training set (10 outlets in total). Hence, we figure out that the 2410 missing values in training set belong to only 3 outlets and the size of these outlets is also missing in the testing set.

```{r}
unique_outs <- unique(train.data %>% select(starts_with("Outlet_")))
unique_outs[,c(1,3)]
```

In order to achieve this, we start by transforming the categorical attributes into dummy variables using `One Hot Encoding` as shown below:

``` {r}
library(DMwR)
library(fastDummies)

train_num <- dummy_cols(unique_outs, select_columns = c('Outlet_Establishment_Year','Outlet_Location_Type','Outlet_Size','Outlet_Type'))
train_num$Outlet_Size_NA <- NULL
na_indices <- which(is.na(train_num$Outlet_Size))
train_num[is.na(train_num$Outlet_Size),c('Outlet_Size_Small','Outlet_Size_Medium','Outlet_Size_High')] <- NA
names(train_num[,-c(1:5)])
```

Then, we predict the missing values for `Outlet_Size` using the K-Nearest Neighbors with K=5. The algorithm reaches out for the 5 closest neighbors (after scaling) for each observation where the attribute is missing and according to a vote assigns a score using a weighted average (`meth='weighAvg`). Therefore, we compute the maximum among the three possible values (Small, Medium and High) and assign it to the corresponding observation.

```{r}
train_num_imp <- knnImputation(train_num[,-c(1:5)], k = 5, scale=T)
for (i in na_indices) {
  out_sizes <- train_num_imp[i,c('Outlet_Size_Medium','Outlet_Size_High','Outlet_Size_Small')]
  max_out_size <- gsub('Outlet_Size_','',colnames(out_sizes)[apply(out_sizes,1,which.max)])
  train.data[train.data$Outlet_Identifier == train_num[i,]$Outlet_Identifier,]$Outlet_Size <- max_out_size
  unique_outs[unique_outs$Outlet_Identifier == train_num[i,]$Outlet_Identifier,]$Outlet_Size <- max_out_size
}
```

We can see here the missing values and their prediction according to 5NN.

```{r}
unique_outs[na_indices,]
train_num_imp[na_indices,c('Outlet_Size_Medium','Outlet_Size_High','Outlet_Size_Small'
                                )]
```

Finally, we check to see that there is still any missing values:

```{r , echo =TRUE}
check.na.values(train.data)
```

We fill the missing values in the testing set with the above-predicted values for each outlet as shown below:

```{r}
test_miss_size_i <- which(is.na(test.data$Outlet_Size))
for (i in test_miss_size_i) {
  out_size <- unique_outs[unique_outs$Outlet_Identifier == test.data[i,]$Outlet_Identifier,]$Outlet_Size
  test.data[i,]$Outlet_Size <- out_size
}
```

After this, we check if there is any missing values in the testing set:

```{r , echo =TRUE}
check.na.values(test.data)
```

```{r , echo =TRUE}
mapping_values <- c("low_fat", "low_fat", "low_fat", "regular", "regular")
names(mapping_values) <- c("LF", "low fat", "Low Fat", "reg", "Regular")

train.data <- train.data %>%
  mutate(Item_Fat_Content = mapping_values[Item_Fat_Content])
  
```

##Feature Engineering:  

###Train:
```{r , echo =TRUE}
train.data = train.data %>% 
  mutate(Years_Operating = 2013 - Outlet_Establishment_Year) %>% 
  mutate(Item_Cat = substr(Item_Identifier,1,2)) %>% 
  # rowwise() %>% 
  mutate(Item_Fat_Content = ifelse(Item_Cat=="NC","not_edible",Item_Fat_Content)) %>% 
  select(-c(Outlet_Establishment_Year)) 

train.data = train.data %>% 
  filter(Item_Visibility>0) %>% 
  group_by(Outlet_Identifier, Item_Type) %>% 
  summarise(Item_Visibility_Avg = mean(Item_Visibility)) %>% 
  merge(train.data, ., by=c("Outlet_Identifier", "Item_Type")) %>% 
  ungroup() %>% 
  mutate(Item_Visibility = ifelse(Item_Visibility==0,Item_Visibility_Avg,Item_Visibility) ) 
  
train.data = train.data %>% 
  mutate(Item_Visibility_Ratio = Item_Visibility/Item_Visibility_Avg ) %>% 
  select(-c(Item_Visibility_Avg)) 
  
```

###Test:
```{r , echo =TRUE}
test.data = test.data %>% 
  mutate(Years_Operating = 2013 - Outlet_Establishment_Year) %>% 
  mutate(Item_Cat = substr(Item_Identifier,1,2)) %>% 
  mutate(Item_Fat_Content = ifelse(Item_Cat=="NC","not_edible",Item_Fat_Content)) %>% 
  select(-c(Outlet_Establishment_Year))

test.data = test.data %>% 
  filter(Item_Visibility>0) %>% 
  group_by(Outlet_Identifier, Item_Type) %>% 
  summarise(Item_Visibility_Avg = mean(Item_Visibility)) %>% 
  merge(test.data, ., by=c("Outlet_Identifier", "Item_Type")) %>% 
  ungroup() %>% 
  mutate(Item_Visibility = ifelse(Item_Visibility==0,Item_Visibility_Avg,Item_Visibility) ) 
  
test.data = test.data %>% 
  mutate(Item_Visibility_Ratio = Item_Visibility/Item_Visibility_Avg ) %>% 
  select(-c(Item_Visibility_Avg)) 
  
```

```{r , echo =TRUE}
setdiff(names(train.data),names(test.data))
```

Finally, we split sample from our training set 1000 observations that we are going to keep aside.

```{r}
set.seed(502)
split <- sample(1:nrow(train.data),1000)
aside.test.data <- train.data[split,]
train.data <- train.data[-split,]
```

### PCA
```{r}
train.data.cat <- Filter(Negate(is.numeric),train.data)
train.data.num <- Filter(is.numeric,train.data)
train.data.dum <- dummy_cols(subset(train.data.cat, select = -Item_Identifier))[,-c(1:7)]
train.data.pca <- data.frame(train.data.num,train.data.dum)
Xtrain <- model.matrix(Item_Outlet_Sales~.,subset(train.data, select = -Item_Identifier))
pca.out <- prcomp(Xtrain[,-1], scale=TRUE, center=TRUE)

myVar=pca.out$sdev^2
explained=myVar/sum(myVar)

plot(explained, xlab="Principal Component", ylab="Proportion of Variance Explained", ylim=c(0,1),type='b')
plot(cumsum(explained), xlab="Principal Component", ylab="Cumulative Proportion of Variance Explained", ylim=c(0,1),type='b')
abline(v=27, col="blue")

Cols=function(vec){
  cols=rainbow(length(unique(vec)))
  return(cols[as.numeric(as.factor(vec))])
}

plot(pca.out$x[,c(1,2)], col=Cols(log(train.data$Item_Outlet_Sales)), pch=19,xlab="Z1",ylab="Z2")
plot(pca.out$x[,c(1,3)], col=Cols(log(train.data$Item_Outlet_Sales)), pch=19,xlab="Z1",ylab="Z3")


# 3d plot of the first 3 significant components of PCA, gradient color of log of sales
color.gradient <- function(x, colors=c("red","yellow","green"), colsteps=100) {
  return(colorRampPalette(colors) (colsteps) [ findInterval(x, seq(min(x),max(x), length.out=colsteps)) ])
}
library(rgl)
plot3d(pca.out$x[,1], pca.out$x[,2], pca.out$x[,3], col = color.gradient(log(train.data$Item_Outlet_Sales + 1)))

```

### Forward Feature Selection
```{r message=FALSE}
library(leaps)
forwardSubset = regsubsets(Item_Outlet_Sales~.,subset(train.data, select = -Item_Identifier), method='backward')
summary(forwardSubset)
names(coef(forwardSubset,9))
plot(forwardSubset,scale='r2')
```

```{r}
library(tree)
myTree = tree(Item_Outlet_Sales~.,train.data,minsize=50, mindev=.0001)
plot(myTree)
text(myTree,pretty=20)

preds <- predict(myTree,train.data)
sqrt(mean((train.data$Item_Outlet_Sales - preds)^2))

myTree = prune.tree(myTree,best=10)
plot(myTree)
text(myTree,pretty=1)
```


Lets try to look at each Outlet individual and how good are the sales for each of them.
```{r}
library(ggplot2)
ggplot(train.data[1:nrow(train.data),], aes(Outlet_Identifier, Item_Outlet_Sales)) +
  geom_boxplot() +
  theme_gray() +
  xlab("Outlet identifier") + 
  ylab("Sales") + 
  ggtitle("Sales vs Outlet identifier")


```
The intuition behind the next plot was to know whether the age of the Outlet does affect the Sales or not. As it shows, it doesn't.
``` {r}
ggplot(train.data[1:nrow(train.data),], aes(as.factor(Years_Operating), Item_Outlet_Sales)) +
  geom_boxplot() +
  theme_gray() 
  xlab("Years of Operation") + 
  ylab("Sales") + 
  ggtitle("Sales vs Years of Operation")
```
Next we try to understand how much is the spread of the price and ranges. 
```{r}

ggplot(train.data, aes(x=Item_MRP)) + 
  geom_density(adjust=1/6) +
  xlab("Max. Retail Price")
  theme_gray()
ggtitle("Spread of Item MRP")

```
```{r}

ggplot(train.data[1:nrow(train.data),], aes(x = Outlet_Type, y = Item_Outlet_Sales, fill = Outlet_Size)) +
  geom_boxplot() +
  theme_gray() +
  xlab("Outlet type") + 
  ylab("Sales") + 
ggtitle("Sales vs Outlet type")


```
```{r}
ggplot(train.data[1:nrow(train.data),], aes(x = Item_Type, y = Item_Outlet_Sales, fill = Outlet_Type)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 70, vjust = 0.5, color = "black")) + 
  xlab("Item type") + 
  ylab("Sales") + 
  ggtitle("Sales vs Item type")
```

```{r}
ggplot(train.data, aes(Item_Type, Item_Visibility_v2, fill = Outlet_Size)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 70, vjust = 0.5, color = "black")) + 
  xlab("Item Type") + 
  ylab("Item Visibility") + 
ggtitle("Item visibility vs Item Type")
```

```{r}
ggplot(train.data, aes(Outlet_Identifier, Item_Visibility_v2)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 70, vjust = 0.5, color = "black")) + 
  xlab("Outlet_Identifier") + 
  ylab("Item Visibility") + 
ggtitle("Item visibility vs Outlet identifier")
```

```{r}
ggplot() + 
geom_density(aes(x=Item_Visibility_v2), colour="red", data=train.data)

```
```{r}
ggplot(train.data[1:nrow(train.data),], aes(Item_Visibility_v2, Item_Outlet_Sales)) +
  geom_point(size = 2.5, aes(colour = factor(Outlet_Type))) +
  theme_light()
  theme(axis.text.x = element_text(angle = 70, vjust = 0.5, color = "black")) + 
  xlab("Item Visibility") + 
  ylab("Item Outlet Sales") +
  ggtitle("Item Sales vs Item Visibility")

```
