---
title: "Project DS502"
author: "Mahdi Alouane and Rahul Pande"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      tidy=TRUE,
                      fig.align='center',
                      tidy.opts=list(width.cutoff=60))
# https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html
```

```{r , echo =TRUE}
setwd("~/r_projects/ds502/project")
train.data <- read.csv('./bigmart_train.csv', stringsAsFactors = FALSE, na.strings = c(""))
test.data <- read.csv('./bigmart_test.csv', stringsAsFactors = FALSE, na.strings = c(""))
```

```{r , echo =TRUE}
check.na.values <- function(df){
  colSums(apply(df, 2, is.na))
}
check.na.values(train.data)
check.na.values(test.data)
```

We have missing values in `Item_Weight` and `Outlet_Size`.


Now, we check the frequencies of categorical variables.

```{r , echo =TRUE}
col_types = lapply(train.data, class)
char_cols = names(col_types[col_types == 'character'])
lapply(train.data[, setdiff(char_cols, c("Item_Identifier"))], table)
```


We aggregate on outlet level to impute outlet size
```{r , echo =TRUE}
setdiff(unique(train.data$Outlet_Identifier), unique(test.data$Outlet_Identifier))
setdiff(unique(test.data$Outlet_Identifier), unique(train.data$Outlet_Identifier))
```

We see that there are no new stores in the test data that are not already encountered in the training data.

```{r , echo =TRUE}
library(tidyverse)
item_weights <- train.data %>%
  group_by(Item_Identifier) %>%
  summarise(
    l_u_weights = length(unique(Item_Weight)),
    u_weights = paste(sort(unique(Item_Weight), na.last = TRUE), collapse = " | "))
```

We see that in some places weights are NA whereas it is not NA in other rows for the same item. We can just use weights from other observations where weight is not NA (For the same item). Also, there are four items for which weights are completely missing. We are going to drop these items.

```{r , echo =TRUE}
train.data.mutate <- train.data %>%
  group_by(Item_Identifier) %>%
  mutate(Item_Weight_Imputed = max(Item_Weight, na.rm = TRUE)) %>%
  ungroup() %>%
  select(-Item_Weight) %>%
  rename(Item_Weight = Item_Weight_Imputed) %>%
  filter(Item_Weight != -Inf)

check.na.values(train.data.mutate)
```

```{r , echo =TRUE}
mapping_values <- c("low_fat", "low_fat", "low_fat", "regular", "regular")
names(mapping_values) <- c("LF", "low fat", "Low Fat", "reg", "Regular")

train.data.mutate <- train.data.mutate %>%
  mutate(Item_Fat_Content = mapping_values[Item_Fat_Content])
  
```
```{r}
#Sales of each store
library(data.table)
hold = data.table(train)
holder.ID = hold[,sum(Item_Outlet_Sales), by = Outlet_Identifier]

barplot(setNames(holder.ID$V1,holder.ID$Outlet_Identifier),horiz = TRUE,width = 2)
#Plot Histogram for each store

```

```{r}
#Size of 
holder.Size = hold[,sum(Item_Outlet_Sales), by = train$Outlet_Size]
barplot(setNames(holder.Size$V1,holder.Size$Outlet_Identifier),width = 2)
```
